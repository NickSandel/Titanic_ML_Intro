{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def load_titanic_data(filename, folder=\"Data\"):\n",
    "    csv_path = os.path.join(folder, filename)\n",
    "    return pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_train = load_titanic_data(\"train.csv\")\n",
    "titanic_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n"
     ]
    }
   ],
   "source": [
    "titanic_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So initial lessons to learn: Age has over 150 missing values which is significant in this dataset size Cabin has 22% population which is very poor could initially transform into a new column of has cabin which is binary, not sure if a location from cabin can be gleaned to help predict survival rates based on where in the ship passengers had cabins? Maybe those with cabins could be more likely to have been in them at the time of sinking?\n",
    "\n",
    "Need to remove PassengerId from training process\n",
    "\n",
    "Only numerical fields which are related numerical - age and fare. The rest are categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.895622895622896"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "204/891 * 100 #Cabin population rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1080 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "titanic_train.hist(bins=50, figsize=(20,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting out a title field from the name seems sensible and setting it's values to true/false\n",
    "Flagging if a passenger had a Cabin or not - perhaps cabin type matters as well\n",
    "Trying to combine Parch and SibSp into a Family feature - saw someone else had done this and sounded sensible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S    644\n",
       "C    168\n",
       "Q     77\n",
       "       2\n",
       "Name: Embarked, dtype: int64"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def AddTitle(data):\n",
    "    data[\"Mr\"] = 0\n",
    "    data[\"Mrs\"] = 0\n",
    "    data[\"Master\"] = 0\n",
    "    data[\"Miss\"] = 0\n",
    "    data[\"Other\"] = 0\n",
    "    data.loc[data[\"Name\"].str.contains(\"Mr.\", regex=False), \"Mr\"] = 1\n",
    "    data.loc[data[\"Name\"].str.contains(\"Mrs.\", regex=False), \"Mrs\"] = 1\n",
    "    data.loc[data[\"Name\"].str.contains(\"Master.\", regex=False), \"Master\"] = 1\n",
    "    data.loc[data[\"Name\"].str.contains(\"Miss.\", regex=False), \"Miss\"] = 1\n",
    "    data.loc[data[\"Mr\"] + data[\"Mrs\"] + data[\"Master\"] + data[\"Miss\"] == 0, \"Other\"] = 1\n",
    "    \n",
    "def AddHasCabin(data):\n",
    "    data[\"HasCabin\"] = data[\"Cabin\"]\n",
    "    data[\"HasCabin\"] = data[\"HasCabin\"].fillna(value=0)\n",
    "    data.loc[data[\"HasCabin\"] != 0, \"HasCabin\"] = 1\n",
    "    \n",
    "def CombineFamily(data):\n",
    "    data[\"Family\"] = data[\"Parch\"] + data[\"SibSp\"]\n",
    "    \n",
    "def CabinType(data):\n",
    "    data[\"CabinLetter\"] = data[\"Cabin\"].str[0]\n",
    "    \n",
    "def AgeBrackets(data):\n",
    "    data[\"Baby\"] = 0\n",
    "    data[\"Child\"] = 0\n",
    "    data[\"YoungAdult\"] = 0\n",
    "    data[\"Adult\"] = 0\n",
    "    data[\"OldAdult\"] = 0\n",
    "    data.loc[data[\"Age\"] < 3, \"Baby\"] = 1\n",
    "    data.loc[(data[\"Age\"] >= 3) & (data[\"Age\"] < 14), \"Child\"] = 1\n",
    "    data.loc[(data[\"Age\"] >= 14) & (data[\"Age\"] < 24), \"YoungAdult\"] = 1\n",
    "    data.loc[(data[\"Age\"] >= 24) & (data[\"Age\"] < 40), \"Adult\"] = 1\n",
    "    data.loc[data[\"Age\"] >= 40, \"OldAdult\"] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diving in and looking at some classification to see how it looks as a first pass. Still need to do more work on unused fields currently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Age', 'Fare', 'Mr', 'Mrs', 'Master', 'Miss', 'Other', 'Family']\n",
      "['Sex', 'Embarked', 'Pclass']\n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "5            6         0       3   \n",
      "6            7         0       1   \n",
      "7            8         0       3   \n",
      "8            9         1       3   \n",
      "9           10         1       2   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "5                                   Moran, Mr. James    male   NaN      0   \n",
      "6                            McCarthy, Mr. Timothy J    male  54.0      0   \n",
      "7                     Palsson, Master. Gosta Leonard    male   2.0      3   \n",
      "8  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0   \n",
      "9                Nasser, Mrs. Nicholas (Adele Achem)  female  14.0      1   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  Mr  Mrs  Master  Miss  \\\n",
      "0      0         A/5 21171   7.2500   NaN        S   1    0       0     0   \n",
      "1      0          PC 17599  71.2833   C85        C   0    1       0     0   \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S   0    0       0     1   \n",
      "3      0            113803  53.1000  C123        S   0    1       0     0   \n",
      "4      0            373450   8.0500   NaN        S   1    0       0     0   \n",
      "5      0            330877   8.4583   NaN        Q   1    0       0     0   \n",
      "6      0             17463  51.8625   E46        S   1    0       0     0   \n",
      "7      1            349909  21.0750   NaN        S   0    0       1     0   \n",
      "8      2            347742  11.1333   NaN        S   0    1       0     0   \n",
      "9      0            237736  30.0708   NaN        C   0    1       0     0   \n",
      "\n",
      "   Other  Family  \n",
      "0      0       1  \n",
      "1      0       1  \n",
      "2      0       0  \n",
      "3      0       1  \n",
      "4      0       0  \n",
      "5      0       0  \n",
      "6      0       0  \n",
      "7      0       4  \n",
      "8      0       2  \n",
      "9      0       1  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 18 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       891 non-null object\n",
      "Mr             891 non-null int64\n",
      "Mrs            891 non-null int64\n",
      "Master         891 non-null int64\n",
      "Miss           891 non-null int64\n",
      "Other          891 non-null int64\n",
      "Family         891 non-null int64\n",
      "dtypes: float64(2), int64(11), object(5)\n",
      "memory usage: 125.4+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names].values\n",
    "\n",
    "titanic_training = titanic_train.copy()\n",
    "\n",
    "def PrepData(data):\n",
    "    AddTitle(data)\n",
    "    #AddHasCabin(data)\n",
    "    CombineFamily(data)\n",
    "    data.Embarked.fillna('S', inplace=True)\n",
    "    data.loc[data[\"Embarked\"] == \"\", \"Embarked\"] = \"S\"\n",
    "    #data.Cabin.fillna('Z', inplace=True)\n",
    "    #data.Age.fillna((data[\"Age\"].median()), inplace=True)\n",
    "    #CabinType(data)\n",
    "    #AgeBrackets(data)\n",
    "    \n",
    "cat_attribs = [\"Sex\",\"Embarked\",\"Pclass\"]\n",
    "#titanic_num = titanic_training.drop([\"PassengerId\",\"Name\",\"Sex\",\"Ticket\",\"Cabin\",\"Embarked\",\"Survived\",\"Parch\",\"SibSp\",\"Pclass\"], axis=1)\n",
    "#num_attribs = list(titanic_num)\n",
    "num_attribs = ['Age', 'Fare', 'Mr', 'Mrs', 'Master', 'Miss', 'Other', 'Family']\n",
    "print(num_attribs)\n",
    "print(cat_attribs)\n",
    "\n",
    "#train_set, test_set = train_test_split(titanic_training, test_size=0.2, random_state=42)\n",
    "\n",
    "   \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Imputer\n",
    "from future_encoders import OneHotEncoder\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('selector', DataFrameSelector(num_attribs)),\n",
    "    ('imputer', Imputer(strategy=\"median\")),\n",
    "    ('std_scaler', StandardScaler()),\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    ('selector', DataFrameSelector(cat_attribs)),\n",
    "    ('cat_encoder', OneHotEncoder(sparse=False)),\n",
    "])\n",
    "\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "full_pipeline = FeatureUnion(transformer_list=[\n",
    "    (\"num_pipeline\", num_pipeline),\n",
    "    (\"cat_pipeline\", cat_pipeline),\n",
    "])\n",
    "\n",
    "#print(\"Babies:\",titanic_training.Baby.sum())\n",
    "#print(\"Children:\",titanic_training.Child.sum())\n",
    "#print(\"Young Adults:\",titanic_training.YoungAdult.sum())\n",
    "#print(\"Adults:\",titanic_training.Adult.sum())\n",
    "#print(\"Old Adults:\",titanic_training.OldAdult.sum())\n",
    "\n",
    "#train_labels, test_labels = train_set[\"Survived\"], test_set[\"Survived\"]\n",
    "train_labels = titanic_training[\"Survived\"]\n",
    "PrepData(titanic_training)\n",
    "\n",
    "print(titanic_training.head(10))\n",
    "print(titanic_training.info())\n",
    "titanic_prepared = full_pipeline.fit_transform(titanic_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', max_iter=5, n_iter=None,\n",
       "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
       "       tol=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "sgd_clf = SGDClassifier(max_iter=5, random_state=42)\n",
    "sgd_clf.fit(titanic_prepared, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.59259259, 0.7003367 , 0.72727273])"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(sgd_clf, titanic_prepared, train_labels, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.78114478, 0.8047138 , 0.8047138 ])"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest_clf = RandomForestClassifier(random_state=42)\n",
    "forest_clf.fit(titanic_prepared, train_labels)\n",
    "cross_val_score(forest_clf, titanic_prepared, train_labels, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.78451178, 0.81144781, 0.8013468 ])"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_clf = KNeighborsClassifier(n_jobs=-1)\n",
    "knn_clf.fit(titanic_prepared, train_labels)\n",
    "cross_val_score(knn_clf, titanic_prepared, train_labels, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial results are poor but promising. I feel like some parameter tuning could help but there's probably more need for improvement in the input parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV] max_features=7, n_estimators=57 .................................\n",
      "[CV]  max_features=7, n_estimators=57, score=0.7877094972067039, total=   0.0s\n",
      "[CV] max_features=7, n_estimators=57 .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_features=7, n_estimators=57, score=0.7877094972067039, total=   0.0s\n",
      "[CV] max_features=7, n_estimators=57 .................................\n",
      "[CV]  max_features=7, n_estimators=57, score=0.8595505617977528, total=   0.0s\n",
      "[CV] max_features=7, n_estimators=57 .................................\n",
      "[CV]  max_features=7, n_estimators=57, score=0.7865168539325843, total=   0.0s\n",
      "[CV] max_features=7, n_estimators=57 .................................\n",
      "[CV]  max_features=7, n_estimators=57, score=0.8135593220338984, total=   0.0s\n",
      "[CV] max_features=8, n_estimators=73 .................................\n",
      "[CV]  max_features=8, n_estimators=73, score=0.7988826815642458, total=   0.0s\n",
      "[CV] max_features=8, n_estimators=73 .................................\n",
      "[CV]  max_features=8, n_estimators=73, score=0.7988826815642458, total=   0.1s\n",
      "[CV] max_features=8, n_estimators=73 .................................\n",
      "[CV]  max_features=8, n_estimators=73, score=0.8651685393258427, total=   0.0s\n",
      "[CV] max_features=8, n_estimators=73 .................................\n",
      "[CV]  max_features=8, n_estimators=73, score=0.7808988764044944, total=   0.1s\n",
      "[CV] max_features=8, n_estimators=73 .................................\n",
      "[CV]  max_features=8, n_estimators=73, score=0.8135593220338984, total=   0.0s\n",
      "[CV] max_features=7, n_estimators=156 ................................\n",
      "[CV]  max_features=7, n_estimators=156, score=0.7821229050279329, total=   0.2s\n",
      "[CV] max_features=7, n_estimators=156 ................................\n",
      "[CV]  max_features=7, n_estimators=156, score=0.7988826815642458, total=   0.2s\n",
      "[CV] max_features=7, n_estimators=156 ................................\n",
      "[CV]  max_features=7, n_estimators=156, score=0.8651685393258427, total=   0.2s\n",
      "[CV] max_features=7, n_estimators=156 ................................\n",
      "[CV]  max_features=7, n_estimators=156, score=0.7808988764044944, total=   0.2s\n",
      "[CV] max_features=7, n_estimators=156 ................................\n",
      "[CV]  max_features=7, n_estimators=156, score=0.8192090395480226, total=   0.2s\n",
      "[CV] max_features=8, n_estimators=81 .................................\n",
      "[CV]  max_features=8, n_estimators=81, score=0.7988826815642458, total=   0.1s\n",
      "[CV] max_features=8, n_estimators=81 .................................\n",
      "[CV]  max_features=8, n_estimators=81, score=0.7932960893854749, total=   0.1s\n",
      "[CV] max_features=8, n_estimators=81 .................................\n",
      "[CV]  max_features=8, n_estimators=81, score=0.8651685393258427, total=   0.1s\n",
      "[CV] max_features=8, n_estimators=81 .................................\n",
      "[CV]  max_features=8, n_estimators=81, score=0.7808988764044944, total=   0.1s\n",
      "[CV] max_features=8, n_estimators=81 .................................\n",
      "[CV]  max_features=8, n_estimators=81, score=0.8135593220338984, total=   0.0s\n",
      "[CV] max_features=9, n_estimators=108 ................................\n",
      "[CV]  max_features=9, n_estimators=108, score=0.8156424581005587, total=   0.1s\n",
      "[CV] max_features=9, n_estimators=108 ................................\n",
      "[CV]  max_features=9, n_estimators=108, score=0.8212290502793296, total=   0.1s\n",
      "[CV] max_features=9, n_estimators=108 ................................\n",
      "[CV]  max_features=9, n_estimators=108, score=0.8651685393258427, total=   0.1s\n",
      "[CV] max_features=9, n_estimators=108 ................................\n",
      "[CV]  max_features=9, n_estimators=108, score=0.7865168539325843, total=   0.1s\n",
      "[CV] max_features=9, n_estimators=108 ................................\n",
      "[CV]  max_features=9, n_estimators=108, score=0.8192090395480226, total=   0.1s\n",
      "[CV] max_features=8, n_estimators=117 ................................\n",
      "[CV]  max_features=8, n_estimators=117, score=0.7988826815642458, total=   0.1s\n",
      "[CV] max_features=8, n_estimators=117 ................................\n",
      "[CV]  max_features=8, n_estimators=117, score=0.7988826815642458, total=   0.1s\n",
      "[CV] max_features=8, n_estimators=117 ................................\n",
      "[CV]  max_features=8, n_estimators=117, score=0.8651685393258427, total=   0.1s\n",
      "[CV] max_features=8, n_estimators=117 ................................\n",
      "[CV]  max_features=8, n_estimators=117, score=0.7865168539325843, total=   0.1s\n",
      "[CV] max_features=8, n_estimators=117 ................................\n",
      "[CV]  max_features=8, n_estimators=117, score=0.807909604519774, total=   0.2s\n",
      "[CV] max_features=8, n_estimators=151 ................................\n",
      "[CV]  max_features=8, n_estimators=151, score=0.7988826815642458, total=   0.2s\n",
      "[CV] max_features=8, n_estimators=151 ................................\n",
      "[CV]  max_features=8, n_estimators=151, score=0.8044692737430168, total=   0.2s\n",
      "[CV] max_features=8, n_estimators=151 ................................\n",
      "[CV]  max_features=8, n_estimators=151, score=0.8595505617977528, total=   0.2s\n",
      "[CV] max_features=8, n_estimators=151 ................................\n",
      "[CV]  max_features=8, n_estimators=151, score=0.7865168539325843, total=   0.2s\n",
      "[CV] max_features=8, n_estimators=151 ................................\n",
      "[CV]  max_features=8, n_estimators=151, score=0.807909604519774, total=   0.2s\n",
      "[CV] max_features=9, n_estimators=87 .................................\n",
      "[CV]  max_features=9, n_estimators=87, score=0.8156424581005587, total=   0.1s\n",
      "[CV] max_features=9, n_estimators=87 .................................\n",
      "[CV]  max_features=9, n_estimators=87, score=0.8156424581005587, total=   0.1s\n",
      "[CV] max_features=9, n_estimators=87 .................................\n",
      "[CV]  max_features=9, n_estimators=87, score=0.8595505617977528, total=   0.1s\n",
      "[CV] max_features=9, n_estimators=87 .................................\n",
      "[CV]  max_features=9, n_estimators=87, score=0.7865168539325843, total=   0.1s\n",
      "[CV] max_features=9, n_estimators=87 .................................\n",
      "[CV]  max_features=9, n_estimators=87, score=0.8135593220338984, total=   0.1s\n",
      "[CV] max_features=7, n_estimators=53 .................................\n",
      "[CV]  max_features=7, n_estimators=53, score=0.7877094972067039, total=   0.0s\n",
      "[CV] max_features=7, n_estimators=53 .................................\n",
      "[CV]  max_features=7, n_estimators=53, score=0.7988826815642458, total=   0.0s\n",
      "[CV] max_features=7, n_estimators=53 .................................\n",
      "[CV]  max_features=7, n_estimators=53, score=0.8539325842696629, total=   0.0s\n",
      "[CV] max_features=7, n_estimators=53 .................................\n",
      "[CV]  max_features=7, n_estimators=53, score=0.7865168539325843, total=   0.0s\n",
      "[CV] max_features=7, n_estimators=53 .................................\n",
      "[CV]  max_features=7, n_estimators=53, score=0.8192090395480226, total=   0.0s\n",
      "[CV] max_features=9, n_estimators=71 .................................\n",
      "[CV]  max_features=9, n_estimators=71, score=0.8156424581005587, total=   0.0s\n",
      "[CV] max_features=9, n_estimators=71 .................................\n",
      "[CV]  max_features=9, n_estimators=71, score=0.8156424581005587, total=   0.0s\n",
      "[CV] max_features=9, n_estimators=71 .................................\n",
      "[CV]  max_features=9, n_estimators=71, score=0.8707865168539326, total=   0.0s\n",
      "[CV] max_features=9, n_estimators=71 .................................\n",
      "[CV]  max_features=9, n_estimators=71, score=0.7865168539325843, total=   0.0s\n",
      "[CV] max_features=9, n_estimators=71 .................................\n",
      "[CV]  max_features=9, n_estimators=71, score=0.8135593220338984, total=   0.0s\n",
      "[CV] max_features=9, n_estimators=197 ................................\n",
      "[CV]  max_features=9, n_estimators=197, score=0.7932960893854749, total=   0.3s\n",
      "[CV] max_features=9, n_estimators=197 ................................\n",
      "[CV]  max_features=9, n_estimators=197, score=0.8044692737430168, total=   0.3s\n",
      "[CV] max_features=9, n_estimators=197 ................................\n",
      "[CV]  max_features=9, n_estimators=197, score=0.8595505617977528, total=   0.3s\n",
      "[CV] max_features=9, n_estimators=197 ................................\n",
      "[CV]  max_features=9, n_estimators=197, score=0.7865168539325843, total=   0.3s\n",
      "[CV] max_features=9, n_estimators=197 ................................\n",
      "[CV]  max_features=9, n_estimators=197, score=0.8192090395480226, total=   0.3s\n",
      "[CV] max_features=9, n_estimators=88 .................................\n",
      "[CV]  max_features=9, n_estimators=88, score=0.8212290502793296, total=   0.1s\n",
      "[CV] max_features=9, n_estimators=88 .................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_features=9, n_estimators=88, score=0.8156424581005587, total=   0.1s\n",
      "[CV] max_features=9, n_estimators=88 .................................\n",
      "[CV]  max_features=9, n_estimators=88, score=0.8651685393258427, total=   0.1s\n",
      "[CV] max_features=9, n_estimators=88 .................................\n",
      "[CV]  max_features=9, n_estimators=88, score=0.7865168539325843, total=   0.1s\n",
      "[CV] max_features=9, n_estimators=88 .................................\n",
      "[CV]  max_features=9, n_estimators=88, score=0.8135593220338984, total=   0.1s\n",
      "[CV] max_features=8, n_estimators=124 ................................\n",
      "[CV]  max_features=8, n_estimators=124, score=0.7988826815642458, total=   0.1s\n",
      "[CV] max_features=8, n_estimators=124 ................................\n",
      "[CV]  max_features=8, n_estimators=124, score=0.7988826815642458, total=   0.1s\n",
      "[CV] max_features=8, n_estimators=124 ................................\n",
      "[CV]  max_features=8, n_estimators=124, score=0.8651685393258427, total=   0.1s\n",
      "[CV] max_features=8, n_estimators=124 ................................\n",
      "[CV]  max_features=8, n_estimators=124, score=0.7865168539325843, total=   0.2s\n",
      "[CV] max_features=8, n_estimators=124 ................................\n",
      "[CV]  max_features=8, n_estimators=124, score=0.807909604519774, total=   0.1s\n",
      "[CV] max_features=8, n_estimators=199 ................................\n",
      "[CV]  max_features=8, n_estimators=199, score=0.7988826815642458, total=   0.3s\n",
      "[CV] max_features=8, n_estimators=199 ................................\n",
      "[CV]  max_features=8, n_estimators=199, score=0.8100558659217877, total=   0.3s\n",
      "[CV] max_features=8, n_estimators=199 ................................\n",
      "[CV]  max_features=8, n_estimators=199, score=0.8539325842696629, total=   0.3s\n",
      "[CV] max_features=8, n_estimators=199 ................................\n",
      "[CV]  max_features=8, n_estimators=199, score=0.7865168539325843, total=   0.3s\n",
      "[CV] max_features=8, n_estimators=199 ................................\n",
      "[CV]  max_features=8, n_estimators=199, score=0.8248587570621468, total=   0.3s\n",
      "[CV] max_features=8, n_estimators=152 ................................\n",
      "[CV]  max_features=8, n_estimators=152, score=0.7988826815642458, total=   0.2s\n",
      "[CV] max_features=8, n_estimators=152 ................................\n",
      "[CV]  max_features=8, n_estimators=152, score=0.8044692737430168, total=   0.2s\n",
      "[CV] max_features=8, n_estimators=152 ................................\n",
      "[CV]  max_features=8, n_estimators=152, score=0.8651685393258427, total=   0.2s\n",
      "[CV] max_features=8, n_estimators=152 ................................\n",
      "[CV]  max_features=8, n_estimators=152, score=0.7865168539325843, total=   0.2s\n",
      "[CV] max_features=8, n_estimators=152 ................................\n",
      "[CV]  max_features=8, n_estimators=152, score=0.807909604519774, total=   0.2s\n",
      "[CV] max_features=8, n_estimators=109 ................................\n",
      "[CV]  max_features=8, n_estimators=109, score=0.7988826815642458, total=   0.1s\n",
      "[CV] max_features=8, n_estimators=109 ................................\n",
      "[CV]  max_features=8, n_estimators=109, score=0.7932960893854749, total=   0.1s\n",
      "[CV] max_features=8, n_estimators=109 ................................\n",
      "[CV]  max_features=8, n_estimators=109, score=0.8595505617977528, total=   0.1s\n",
      "[CV] max_features=8, n_estimators=109 ................................\n",
      "[CV]  max_features=8, n_estimators=109, score=0.7865168539325843, total=   0.1s\n",
      "[CV] max_features=8, n_estimators=109 ................................\n",
      "[CV]  max_features=8, n_estimators=109, score=0.807909604519774, total=   0.1s\n",
      "[CV] max_features=9, n_estimators=40 .................................\n",
      "[CV]  max_features=9, n_estimators=40, score=0.8268156424581006, total=   0.0s\n",
      "[CV] max_features=9, n_estimators=40 .................................\n",
      "[CV]  max_features=9, n_estimators=40, score=0.8044692737430168, total=   0.0s\n",
      "[CV] max_features=9, n_estimators=40 .................................\n",
      "[CV]  max_features=9, n_estimators=40, score=0.8707865168539326, total=   0.0s\n",
      "[CV] max_features=9, n_estimators=40 .................................\n",
      "[CV]  max_features=9, n_estimators=40, score=0.7921348314606742, total=   0.0s\n",
      "[CV] max_features=9, n_estimators=40 .................................\n",
      "[CV]  max_features=9, n_estimators=40, score=0.8135593220338984, total=   0.0s\n",
      "[CV] max_features=9, n_estimators=73 .................................\n",
      "[CV]  max_features=9, n_estimators=73, score=0.8156424581005587, total=   0.0s\n",
      "[CV] max_features=9, n_estimators=73 .................................\n",
      "[CV]  max_features=9, n_estimators=73, score=0.8156424581005587, total=   0.0s\n",
      "[CV] max_features=9, n_estimators=73 .................................\n",
      "[CV]  max_features=9, n_estimators=73, score=0.8595505617977528, total=   0.0s\n",
      "[CV] max_features=9, n_estimators=73 .................................\n",
      "[CV]  max_features=9, n_estimators=73, score=0.7865168539325843, total=   0.0s\n",
      "[CV] max_features=9, n_estimators=73 .................................\n",
      "[CV]  max_features=9, n_estimators=73, score=0.8135593220338984, total=   0.0s\n",
      "[CV] max_features=8, n_estimators=106 ................................\n",
      "[CV]  max_features=8, n_estimators=106, score=0.7932960893854749, total=   0.1s\n",
      "[CV] max_features=8, n_estimators=106 ................................\n",
      "[CV]  max_features=8, n_estimators=106, score=0.7988826815642458, total=   0.1s\n",
      "[CV] max_features=8, n_estimators=106 ................................\n",
      "[CV]  max_features=8, n_estimators=106, score=0.8595505617977528, total=   0.1s\n",
      "[CV] max_features=8, n_estimators=106 ................................\n",
      "[CV]  max_features=8, n_estimators=106, score=0.7865168539325843, total=   0.1s\n",
      "[CV] max_features=8, n_estimators=106 ................................\n",
      "[CV]  max_features=8, n_estimators=106, score=0.8135593220338984, total=   0.1s\n",
      "[CV] max_features=7, n_estimators=52 .................................\n",
      "[CV]  max_features=7, n_estimators=52, score=0.7932960893854749, total=   0.0s\n",
      "[CV] max_features=7, n_estimators=52 .................................\n",
      "[CV]  max_features=7, n_estimators=52, score=0.7988826815642458, total=   0.0s\n",
      "[CV] max_features=7, n_estimators=52 .................................\n",
      "[CV]  max_features=7, n_estimators=52, score=0.8595505617977528, total=   0.0s\n",
      "[CV] max_features=7, n_estimators=52 .................................\n",
      "[CV]  max_features=7, n_estimators=52, score=0.7865168539325843, total=   0.0s\n",
      "[CV] max_features=7, n_estimators=52 .................................\n",
      "[CV]  max_features=7, n_estimators=52, score=0.8192090395480226, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   20.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise',\n",
       "          estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False),\n",
       "          fit_params=None, iid=True, n_iter=20, n_jobs=1,\n",
       "          param_distributions={'max_features': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001BEB560E4E0>, 'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001BEB68AF550>},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score=False, scoring=None, verbose=3)"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "param_grid = {\n",
    "        'n_estimators': randint(low=20, high=200),\n",
    "        'max_features': randint(low=7, high=10),\n",
    "    }\n",
    "\n",
    "forest_clf = RandomForestClassifier(random_state=42)\n",
    "grid_search = RandomizedSearchCV(forest_clf, param_grid, n_iter = 20, cv=5, verbose=3, return_train_score=False)\n",
    "grid_search.fit(titanic_prepared, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_features': 9, 'n_estimators': 108}\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features=9, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=108, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False)\n",
      "0.8983086739117798 max_features: 7 n_estimators: 57\n",
      "0.9008039805905674 max_features: 8 n_estimators: 73\n",
      "0.8995571924766518 max_features: 7 n_estimators: 156\n",
      "0.9001808023903551 max_features: 8 n_estimators: 81\n",
      "0.9063933040070528 max_features: 9 n_estimators: 108\n",
      "0.9008039805905674 max_features: 8 n_estimators: 117\n",
      "0.9008039805905674 max_features: 8 n_estimators: 151\n",
      "0.9045340337332909 max_features: 9 n_estimators: 87\n",
      "0.8995571924766518 max_features: 7 n_estimators: 53\n",
      "0.9057739713047366 max_features: 9 n_estimators: 71\n",
      "0.9014267279726507 max_features: 9 n_estimators: 197\n",
      "0.9057739713047366 max_features: 9 n_estimators: 88\n",
      "0.9008039805905674 max_features: 8 n_estimators: 124\n",
      "0.90267093384844 max_features: 8 n_estimators: 199\n",
      "0.9014267279726507 max_features: 8 n_estimators: 152\n",
      "0.8995571924766518 max_features: 8 n_estimators: 109\n",
      "0.9063933040070528 max_features: 9 n_estimators: 40\n",
      "0.9045340337332909 max_features: 9 n_estimators: 73\n",
      "0.9001808023903551 max_features: 8 n_estimators: 106\n",
      "0.9008039805905674 max_features: 7 n_estimators: 52\n",
      "[[0.9063933040070528, 9, 108], [0.9063933040070528, 9, 40], [0.9057739713047366, 9, 88], [0.9057739713047366, 9, 71], [0.9045340337332909, 9, 87], [0.9045340337332909, 9, 73], [0.90267093384844, 8, 199], [0.9014267279726507, 9, 197], [0.9014267279726507, 8, 152], [0.9008039805905674, 8, 151], [0.9008039805905674, 8, 124], [0.9008039805905674, 8, 117], [0.9008039805905674, 8, 73], [0.9008039805905674, 7, 52], [0.9001808023903551, 8, 106], [0.9001808023903551, 8, 81], [0.8995571924766518, 8, 109], [0.8995571924766518, 7, 156], [0.8995571924766518, 7, 53], [0.8983086739117798, 7, 57]]\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_estimator_)\n",
    "\n",
    "array = []\n",
    "cvres = grid_search.cv_results_\n",
    "for mean_score, features, estimators in zip(cvres[\"mean_test_score\"], cvres[\"param_max_features\"], cvres[\"param_n_estimators\"]):\n",
    "    print(np.sqrt(mean_score), 'max_features:', features, 'n_estimators:', estimators)\n",
    "    array.append([np.sqrt(mean_score),features,estimators])\n",
    "    \n",
    "print(sorted(array, reverse=True))\n",
    "\n",
    "#feature_importances = grid_search.best_estimator_.feature_importances_\n",
    "#sorted(feature_importances)\n",
    "\n",
    "#extra_attribs = [\"Mr\",\"Mrs\",\"Master\",\"Miss\",\"Other\",\"HasCabin\",\"Family\",\"CabinLetter\",\"Baby\",\"Child\",\"YoungAdult\",\"Adult\",\"OldAdult\"]\n",
    "#cat_encoder = cat_pipeline.named_steps[\"cat_encoder\"]\n",
    "#cat_one_hot_attribs = list(cat_encoder.categories_[0]) + list(cat_encoder.categories_[1]) + list(cat_encoder.categories_[2]) + list(cat_encoder.categories_[3])\n",
    "#print(list(titanic_num), cat_one_hot_attribs)\n",
    "#attributes = list(titanic_num) + cat_one_hot_attribs\n",
    "#sorted(zip(feature_importances, attributes), reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.077636</td>\n",
       "      <td>0.002603</td>\n",
       "      <td>0.821549</td>\n",
       "      <td>9</td>\n",
       "      <td>40</td>\n",
       "      <td>{'max_features': 9, 'n_estimators': 40}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.826816</td>\n",
       "      <td>0.804469</td>\n",
       "      <td>0.870787</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.813559</td>\n",
       "      <td>0.008938</td>\n",
       "      <td>0.002156</td>\n",
       "      <td>0.027093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.200174</td>\n",
       "      <td>0.013767</td>\n",
       "      <td>0.821549</td>\n",
       "      <td>9</td>\n",
       "      <td>108</td>\n",
       "      <td>{'max_features': 9, 'n_estimators': 108}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.815642</td>\n",
       "      <td>0.821229</td>\n",
       "      <td>0.865169</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.819209</td>\n",
       "      <td>0.010609</td>\n",
       "      <td>0.006136</td>\n",
       "      <td>0.025167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.138508</td>\n",
       "      <td>0.008203</td>\n",
       "      <td>0.820426</td>\n",
       "      <td>9</td>\n",
       "      <td>71</td>\n",
       "      <td>{'max_features': 9, 'n_estimators': 71}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.815642</td>\n",
       "      <td>0.815642</td>\n",
       "      <td>0.870787</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.813559</td>\n",
       "      <td>0.002358</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>0.027476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.165399</td>\n",
       "      <td>0.004412</td>\n",
       "      <td>0.820426</td>\n",
       "      <td>9</td>\n",
       "      <td>88</td>\n",
       "      <td>{'max_features': 9, 'n_estimators': 88}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.821229</td>\n",
       "      <td>0.815642</td>\n",
       "      <td>0.865169</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.813559</td>\n",
       "      <td>0.009690</td>\n",
       "      <td>0.003828</td>\n",
       "      <td>0.025372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.133107</td>\n",
       "      <td>0.011478</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>9</td>\n",
       "      <td>73</td>\n",
       "      <td>{'max_features': 9, 'n_estimators': 73}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.815642</td>\n",
       "      <td>0.815642</td>\n",
       "      <td>0.859551</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.813559</td>\n",
       "      <td>0.002059</td>\n",
       "      <td>0.003503</td>\n",
       "      <td>0.023431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.165323</td>\n",
       "      <td>0.008933</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>9</td>\n",
       "      <td>87</td>\n",
       "      <td>{'max_features': 9, 'n_estimators': 87}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.815642</td>\n",
       "      <td>0.815642</td>\n",
       "      <td>0.859551</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.813559</td>\n",
       "      <td>0.008477</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.023431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.364055</td>\n",
       "      <td>0.017971</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>8</td>\n",
       "      <td>199</td>\n",
       "      <td>{'max_features': 8, 'n_estimators': 199}</td>\n",
       "      <td>7</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.810056</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.824859</td>\n",
       "      <td>0.014695</td>\n",
       "      <td>0.006817</td>\n",
       "      <td>0.023265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.302048</td>\n",
       "      <td>0.015948</td>\n",
       "      <td>0.812570</td>\n",
       "      <td>8</td>\n",
       "      <td>152</td>\n",
       "      <td>{'max_features': 8, 'n_estimators': 152}</td>\n",
       "      <td>8</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.804469</td>\n",
       "      <td>0.865169</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.807910</td>\n",
       "      <td>0.016096</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.027266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.371401</td>\n",
       "      <td>0.019786</td>\n",
       "      <td>0.812570</td>\n",
       "      <td>9</td>\n",
       "      <td>197</td>\n",
       "      <td>{'max_features': 9, 'n_estimators': 197}</td>\n",
       "      <td>8</td>\n",
       "      <td>0.793296</td>\n",
       "      <td>0.804469</td>\n",
       "      <td>0.859551</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.819209</td>\n",
       "      <td>0.009968</td>\n",
       "      <td>0.007187</td>\n",
       "      <td>0.025944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.227086</td>\n",
       "      <td>0.013999</td>\n",
       "      <td>0.811448</td>\n",
       "      <td>8</td>\n",
       "      <td>124</td>\n",
       "      <td>{'max_features': 8, 'n_estimators': 124}</td>\n",
       "      <td>10</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.865169</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.807910</td>\n",
       "      <td>0.006788</td>\n",
       "      <td>0.001794</td>\n",
       "      <td>0.027688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.093271</td>\n",
       "      <td>0.006519</td>\n",
       "      <td>0.811448</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>{'max_features': 7, 'n_estimators': 52}</td>\n",
       "      <td>10</td>\n",
       "      <td>0.793296</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.859551</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.819209</td>\n",
       "      <td>0.007934</td>\n",
       "      <td>0.005084</td>\n",
       "      <td>0.026388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.278349</td>\n",
       "      <td>0.013939</td>\n",
       "      <td>0.811448</td>\n",
       "      <td>8</td>\n",
       "      <td>151</td>\n",
       "      <td>{'max_features': 8, 'n_estimators': 151}</td>\n",
       "      <td>10</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.804469</td>\n",
       "      <td>0.859551</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.807910</td>\n",
       "      <td>0.006505</td>\n",
       "      <td>0.003584</td>\n",
       "      <td>0.025108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.222684</td>\n",
       "      <td>0.012003</td>\n",
       "      <td>0.811448</td>\n",
       "      <td>8</td>\n",
       "      <td>117</td>\n",
       "      <td>{'max_features': 8, 'n_estimators': 117}</td>\n",
       "      <td>10</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.865169</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.807910</td>\n",
       "      <td>0.011200</td>\n",
       "      <td>0.000898</td>\n",
       "      <td>0.027688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.142899</td>\n",
       "      <td>0.006391</td>\n",
       "      <td>0.811448</td>\n",
       "      <td>8</td>\n",
       "      <td>73</td>\n",
       "      <td>{'max_features': 8, 'n_estimators': 73}</td>\n",
       "      <td>10</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.865169</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.813559</td>\n",
       "      <td>0.005084</td>\n",
       "      <td>0.003316</td>\n",
       "      <td>0.028763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.149833</td>\n",
       "      <td>0.009232</td>\n",
       "      <td>0.810325</td>\n",
       "      <td>8</td>\n",
       "      <td>81</td>\n",
       "      <td>{'max_features': 8, 'n_estimators': 81}</td>\n",
       "      <td>15</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.793296</td>\n",
       "      <td>0.865169</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.813559</td>\n",
       "      <td>0.003363</td>\n",
       "      <td>0.008237</td>\n",
       "      <td>0.029334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.192930</td>\n",
       "      <td>0.012622</td>\n",
       "      <td>0.810325</td>\n",
       "      <td>8</td>\n",
       "      <td>106</td>\n",
       "      <td>{'max_features': 8, 'n_estimators': 106}</td>\n",
       "      <td>15</td>\n",
       "      <td>0.793296</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.859551</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.813559</td>\n",
       "      <td>0.005305</td>\n",
       "      <td>0.003795</td>\n",
       "      <td>0.026153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.092175</td>\n",
       "      <td>0.006878</td>\n",
       "      <td>0.809203</td>\n",
       "      <td>7</td>\n",
       "      <td>53</td>\n",
       "      <td>{'max_features': 7, 'n_estimators': 53}</td>\n",
       "      <td>17</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.819209</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.005604</td>\n",
       "      <td>0.025231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.195938</td>\n",
       "      <td>0.013828</td>\n",
       "      <td>0.809203</td>\n",
       "      <td>8</td>\n",
       "      <td>109</td>\n",
       "      <td>{'max_features': 8, 'n_estimators': 109}</td>\n",
       "      <td>17</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.793296</td>\n",
       "      <td>0.859551</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.807910</td>\n",
       "      <td>0.010997</td>\n",
       "      <td>0.003631</td>\n",
       "      <td>0.026111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.278822</td>\n",
       "      <td>0.013510</td>\n",
       "      <td>0.809203</td>\n",
       "      <td>7</td>\n",
       "      <td>156</td>\n",
       "      <td>{'max_features': 7, 'n_estimators': 156}</td>\n",
       "      <td>17</td>\n",
       "      <td>0.782123</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.865169</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.819209</td>\n",
       "      <td>0.007270</td>\n",
       "      <td>0.003362</td>\n",
       "      <td>0.031215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.105788</td>\n",
       "      <td>0.005812</td>\n",
       "      <td>0.806958</td>\n",
       "      <td>7</td>\n",
       "      <td>57</td>\n",
       "      <td>{'max_features': 7, 'n_estimators': 57}</td>\n",
       "      <td>20</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.859551</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.813559</td>\n",
       "      <td>0.003126</td>\n",
       "      <td>0.000389</td>\n",
       "      <td>0.028170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  mean_score_time  mean_test_score param_max_features  \\\n",
       "16       0.077636         0.002603         0.821549                  9   \n",
       "4        0.200174         0.013767         0.821549                  9   \n",
       "9        0.138508         0.008203         0.820426                  9   \n",
       "11       0.165399         0.004412         0.820426                  9   \n",
       "17       0.133107         0.011478         0.818182                  9   \n",
       "7        0.165323         0.008933         0.818182                  9   \n",
       "13       0.364055         0.017971         0.814815                  8   \n",
       "14       0.302048         0.015948         0.812570                  8   \n",
       "10       0.371401         0.019786         0.812570                  9   \n",
       "12       0.227086         0.013999         0.811448                  8   \n",
       "19       0.093271         0.006519         0.811448                  7   \n",
       "6        0.278349         0.013939         0.811448                  8   \n",
       "5        0.222684         0.012003         0.811448                  8   \n",
       "1        0.142899         0.006391         0.811448                  8   \n",
       "3        0.149833         0.009232         0.810325                  8   \n",
       "18       0.192930         0.012622         0.810325                  8   \n",
       "8        0.092175         0.006878         0.809203                  7   \n",
       "15       0.195938         0.013828         0.809203                  8   \n",
       "2        0.278822         0.013510         0.809203                  7   \n",
       "0        0.105788         0.005812         0.806958                  7   \n",
       "\n",
       "   param_n_estimators                                    params  \\\n",
       "16                 40   {'max_features': 9, 'n_estimators': 40}   \n",
       "4                 108  {'max_features': 9, 'n_estimators': 108}   \n",
       "9                  71   {'max_features': 9, 'n_estimators': 71}   \n",
       "11                 88   {'max_features': 9, 'n_estimators': 88}   \n",
       "17                 73   {'max_features': 9, 'n_estimators': 73}   \n",
       "7                  87   {'max_features': 9, 'n_estimators': 87}   \n",
       "13                199  {'max_features': 8, 'n_estimators': 199}   \n",
       "14                152  {'max_features': 8, 'n_estimators': 152}   \n",
       "10                197  {'max_features': 9, 'n_estimators': 197}   \n",
       "12                124  {'max_features': 8, 'n_estimators': 124}   \n",
       "19                 52   {'max_features': 7, 'n_estimators': 52}   \n",
       "6                 151  {'max_features': 8, 'n_estimators': 151}   \n",
       "5                 117  {'max_features': 8, 'n_estimators': 117}   \n",
       "1                  73   {'max_features': 8, 'n_estimators': 73}   \n",
       "3                  81   {'max_features': 8, 'n_estimators': 81}   \n",
       "18                106  {'max_features': 8, 'n_estimators': 106}   \n",
       "8                  53   {'max_features': 7, 'n_estimators': 53}   \n",
       "15                109  {'max_features': 8, 'n_estimators': 109}   \n",
       "2                 156  {'max_features': 7, 'n_estimators': 156}   \n",
       "0                  57   {'max_features': 7, 'n_estimators': 57}   \n",
       "\n",
       "    rank_test_score  split0_test_score  split1_test_score  split2_test_score  \\\n",
       "16                1           0.826816           0.804469           0.870787   \n",
       "4                 1           0.815642           0.821229           0.865169   \n",
       "9                 3           0.815642           0.815642           0.870787   \n",
       "11                3           0.821229           0.815642           0.865169   \n",
       "17                5           0.815642           0.815642           0.859551   \n",
       "7                 5           0.815642           0.815642           0.859551   \n",
       "13                7           0.798883           0.810056           0.853933   \n",
       "14                8           0.798883           0.804469           0.865169   \n",
       "10                8           0.793296           0.804469           0.859551   \n",
       "12               10           0.798883           0.798883           0.865169   \n",
       "19               10           0.793296           0.798883           0.859551   \n",
       "6                10           0.798883           0.804469           0.859551   \n",
       "5                10           0.798883           0.798883           0.865169   \n",
       "1                10           0.798883           0.798883           0.865169   \n",
       "3                15           0.798883           0.793296           0.865169   \n",
       "18               15           0.793296           0.798883           0.859551   \n",
       "8                17           0.787709           0.798883           0.853933   \n",
       "15               17           0.798883           0.793296           0.859551   \n",
       "2                17           0.782123           0.798883           0.865169   \n",
       "0                20           0.787709           0.787709           0.859551   \n",
       "\n",
       "    split3_test_score  split4_test_score  std_fit_time  std_score_time  \\\n",
       "16           0.792135           0.813559      0.008938        0.002156   \n",
       "4            0.786517           0.819209      0.010609        0.006136   \n",
       "9            0.786517           0.813559      0.002358        0.000743   \n",
       "11           0.786517           0.813559      0.009690        0.003828   \n",
       "17           0.786517           0.813559      0.002059        0.003503   \n",
       "7            0.786517           0.813559      0.008477        0.003922   \n",
       "13           0.786517           0.824859      0.014695        0.006817   \n",
       "14           0.786517           0.807910      0.016096        0.000143   \n",
       "10           0.786517           0.819209      0.009968        0.007187   \n",
       "12           0.786517           0.807910      0.006788        0.001794   \n",
       "19           0.786517           0.819209      0.007934        0.005084   \n",
       "6            0.786517           0.807910      0.006505        0.003584   \n",
       "5            0.786517           0.807910      0.011200        0.000898   \n",
       "1            0.780899           0.813559      0.005084        0.003316   \n",
       "3            0.780899           0.813559      0.003363        0.008237   \n",
       "18           0.786517           0.813559      0.005305        0.003795   \n",
       "8            0.786517           0.819209      0.003935        0.005604   \n",
       "15           0.786517           0.807910      0.010997        0.003631   \n",
       "2            0.780899           0.819209      0.007270        0.003362   \n",
       "0            0.786517           0.813559      0.003126        0.000389   \n",
       "\n",
       "    std_test_score  \n",
       "16        0.027093  \n",
       "4         0.025167  \n",
       "9         0.027476  \n",
       "11        0.025372  \n",
       "17        0.023431  \n",
       "7         0.023431  \n",
       "13        0.023265  \n",
       "14        0.027266  \n",
       "10        0.025944  \n",
       "12        0.027688  \n",
       "19        0.026388  \n",
       "6         0.025108  \n",
       "5         0.027688  \n",
       "1         0.028763  \n",
       "3         0.029334  \n",
       "18        0.026153  \n",
       "8         0.025231  \n",
       "15        0.026111  \n",
       "2         0.031215  \n",
       "0         0.028170  "
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df = pd.DataFrame(grid_search.cv_results_).sort_values(by='rank_test_score')\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV] n_neighbors=3, weights=uniform ..................................\n",
      "[CV]  n_neighbors=3, weights=uniform, score=0.7653631284916201, total=   0.0s\n",
      "[CV] n_neighbors=3, weights=uniform ..................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_neighbors=3, weights=uniform, score=0.8044692737430168, total=   0.0s\n",
      "[CV] n_neighbors=3, weights=uniform ..................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_neighbors=3, weights=uniform, score=0.8089887640449438, total=   0.0s\n",
      "[CV] n_neighbors=3, weights=uniform ..................................\n",
      "[CV]  n_neighbors=3, weights=uniform, score=0.8033707865168539, total=   0.0s\n",
      "[CV] n_neighbors=3, weights=uniform ..................................\n",
      "[CV]  n_neighbors=3, weights=uniform, score=0.807909604519774, total=   0.0s\n",
      "[CV] n_neighbors=3, weights=distance .................................\n",
      "[CV]  n_neighbors=3, weights=distance, score=0.7877094972067039, total=   0.0s\n",
      "[CV] n_neighbors=3, weights=distance .................................\n",
      "[CV]  n_neighbors=3, weights=distance, score=0.776536312849162, total=   0.0s\n",
      "[CV] n_neighbors=3, weights=distance .................................\n",
      "[CV]  n_neighbors=3, weights=distance, score=0.8089887640449438, total=   0.0s\n",
      "[CV] n_neighbors=3, weights=distance .................................\n",
      "[CV]  n_neighbors=3, weights=distance, score=0.7808988764044944, total=   0.0s\n",
      "[CV] n_neighbors=3, weights=distance .................................\n",
      "[CV]  n_neighbors=3, weights=distance, score=0.807909604519774, total=   0.0s\n",
      "[CV] n_neighbors=4, weights=uniform ..................................\n",
      "[CV]  n_neighbors=4, weights=uniform, score=0.7653631284916201, total=   0.0s\n",
      "[CV] n_neighbors=4, weights=uniform ..................................\n",
      "[CV]  n_neighbors=4, weights=uniform, score=0.8044692737430168, total=   0.0s\n",
      "[CV] n_neighbors=4, weights=uniform ..................................\n",
      "[CV]  n_neighbors=4, weights=uniform, score=0.8314606741573034, total=   0.0s\n",
      "[CV] n_neighbors=4, weights=uniform ..................................\n",
      "[CV]  n_neighbors=4, weights=uniform, score=0.8202247191011236, total=   0.0s\n",
      "[CV] n_neighbors=4, weights=uniform ..................................\n",
      "[CV]  n_neighbors=4, weights=uniform, score=0.8022598870056498, total=   0.0s\n",
      "[CV] n_neighbors=4, weights=distance .................................\n",
      "[CV]  n_neighbors=4, weights=distance, score=0.770949720670391, total=   0.0s\n",
      "[CV] n_neighbors=4, weights=distance .................................\n",
      "[CV]  n_neighbors=4, weights=distance, score=0.7877094972067039, total=   0.0s\n",
      "[CV] n_neighbors=4, weights=distance .................................\n",
      "[CV]  n_neighbors=4, weights=distance, score=0.8089887640449438, total=   0.0s\n",
      "[CV] n_neighbors=4, weights=distance .................................\n",
      "[CV]  n_neighbors=4, weights=distance, score=0.7921348314606742, total=   0.0s\n",
      "[CV] n_neighbors=4, weights=distance .................................\n",
      "[CV]  n_neighbors=4, weights=distance, score=0.807909604519774, total=   0.0s\n",
      "[CV] n_neighbors=5, weights=uniform ..................................\n",
      "[CV]  n_neighbors=5, weights=uniform, score=0.7932960893854749, total=   0.0s\n",
      "[CV] n_neighbors=5, weights=uniform ..................................\n",
      "[CV]  n_neighbors=5, weights=uniform, score=0.7988826815642458, total=   0.0s\n",
      "[CV] n_neighbors=5, weights=uniform ..................................\n",
      "[CV]  n_neighbors=5, weights=uniform, score=0.8089887640449438, total=   0.0s\n",
      "[CV] n_neighbors=5, weights=uniform ..................................\n",
      "[CV]  n_neighbors=5, weights=uniform, score=0.8146067415730337, total=   0.0s\n",
      "[CV] n_neighbors=5, weights=uniform ..................................\n",
      "[CV]  n_neighbors=5, weights=uniform, score=0.807909604519774, total=   0.0s\n",
      "[CV] n_neighbors=5, weights=distance .................................\n",
      "[CV]  n_neighbors=5, weights=distance, score=0.7932960893854749, total=   0.0s\n",
      "[CV] n_neighbors=5, weights=distance .................................\n",
      "[CV]  n_neighbors=5, weights=distance, score=0.7821229050279329, total=   0.0s\n",
      "[CV] n_neighbors=5, weights=distance .................................\n",
      "[CV]  n_neighbors=5, weights=distance, score=0.797752808988764, total=   0.0s\n",
      "[CV] n_neighbors=5, weights=distance .................................\n",
      "[CV]  n_neighbors=5, weights=distance, score=0.7921348314606742, total=   0.0s\n",
      "[CV] n_neighbors=5, weights=distance .................................\n",
      "[CV]  n_neighbors=5, weights=distance, score=0.807909604519774, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    6.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'n_neighbors': [3, 4, 5], 'weights': ['uniform', 'distance']}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=3)"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "    {'n_neighbors': [3,4,5], 'weights': [\"uniform\",\"distance\"]},\n",
    "]\n",
    "\n",
    "knn_clf = KNeighborsClassifier(n_jobs=-1)\n",
    "grid_search_knn = GridSearchCV(knn_clf, param_grid, cv=5, verbose=3)\n",
    "grid_search_knn.fit(titanic_prepared, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 4, 'weights': 'uniform'}\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=-1, n_neighbors=4, p=2,\n",
      "           weights='uniform')\n",
      "0.8932971498777985 0.797979797979798 {'n_neighbors': 3, 'weights': 'uniform'}\n",
      "0.8901506196714458 0.792368125701459 {'n_neighbors': 3, 'weights': 'distance'}\n",
      "0.8970584176706692 0.8047138047138047 {'n_neighbors': 4, 'weights': 'uniform'}\n",
      "0.8907808148793546 0.7934904601571269 {'n_neighbors': 4, 'weights': 'distance'}\n",
      "0.8970584176706692 0.8047138047138047 {'n_neighbors': 5, 'weights': 'uniform'}\n",
      "0.8914105645620286 0.7946127946127947 {'n_neighbors': 5, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "print(grid_search_knn.best_params_)\n",
    "print(grid_search_knn.best_estimator_)\n",
    "\n",
    "cvres = grid_search_knn.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(np.sqrt(mean_score), mean_score, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So lets say I'm happy enough with the Random Forest best estimator - how to export?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7852349 , 0.81208054, 0.8590604 , 0.85135135, 0.81756757,\n",
       "       0.84459459])"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_clf = RandomForestClassifier(random_state=42,max_features= 9, n_estimators = 108)\n",
    "forest_clf.fit(titanic_prepared, train_labels)\n",
    "cross_val_score(forest_clf, titanic_prepared, train_labels, cv=6, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9820426487093153\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "predictions = forest_clf.predict(titanic_prepared)\n",
    "print(accuracy_score(train_labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.38623105 -0.49741333  0.86120071 -0.45617155 -0.22999288 -0.47896948\n",
      " -0.13050529 -0.5534426   0.          1.          0.          1.\n",
      "  0.          0.          0.          1.        ]\n",
      "[-0.56573646 -0.50244517  0.85053175 -0.4039621  -0.21680296 -0.50665528\n",
      " -0.1767767   0.05915988  0.          1.          0.          0.\n",
      "  1.          0.          0.          1.        ]\n",
      "['Age', 'Fare', 'Mr', 'Mrs', 'Master', 'Miss', 'Other', 'Family'] ['Sex', 'Embarked', 'Pclass']\n",
      "     PassengerId  Survived\n",
      "0            892         0\n",
      "1            893         0\n",
      "2            894         0\n",
      "3            895         0\n",
      "4            896         1\n",
      "5            897         0\n",
      "6            898         0\n",
      "7            899         0\n",
      "8            900         1\n",
      "9            901         0\n",
      "10           902         0\n",
      "11           903         0\n",
      "12           904         1\n",
      "13           905         0\n",
      "14           906         1\n",
      "15           907         1\n",
      "16           908         0\n",
      "17           909         1\n",
      "18           910         0\n",
      "19           911         0\n",
      "20           912         0\n",
      "21           913         1\n",
      "22           914         1\n",
      "23           915         1\n",
      "24           916         1\n",
      "25           917         0\n",
      "26           918         1\n",
      "27           919         1\n",
      "28           920         0\n",
      "29           921         0\n",
      "..           ...       ...\n",
      "388         1280         0\n",
      "389         1281         0\n",
      "390         1282         0\n",
      "391         1283         1\n",
      "392         1284         1\n",
      "393         1285         0\n",
      "394         1286         0\n",
      "395         1287         1\n",
      "396         1288         0\n",
      "397         1289         1\n",
      "398         1290         0\n",
      "399         1291         0\n",
      "400         1292         1\n",
      "401         1293         0\n",
      "402         1294         1\n",
      "403         1295         0\n",
      "404         1296         0\n",
      "405         1297         1\n",
      "406         1298         0\n",
      "407         1299         0\n",
      "408         1300         0\n",
      "409         1301         1\n",
      "410         1302         0\n",
      "411         1303         1\n",
      "412         1304         0\n",
      "413         1305         0\n",
      "414         1306         1\n",
      "415         1307         0\n",
      "416         1308         0\n",
      "417         1309         1\n",
      "\n",
      "[418 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "titanic_test = load_titanic_data(\"test.csv\")\n",
    "PrepData(titanic_test)\n",
    "\n",
    "titanic_test_prepared = full_pipeline.fit_transform(titanic_test)\n",
    "print(titanic_test_prepared[0])\n",
    "print(titanic_prepared[0])\n",
    "\n",
    "print(list(num_attribs), cat_attribs)\n",
    "\n",
    "test_predictions = forest_clf.predict(titanic_test_prepared)\n",
    "titanic_test_output = [titanic_test, test_predictions]\n",
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": titanic_test[\"PassengerId\"],\n",
    "        \"Survived\": test_predictions\n",
    "    })\n",
    "print(submission)\n",
    "submission.to_csv('titanic_predictions_RF_MF_9_NE_108.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
